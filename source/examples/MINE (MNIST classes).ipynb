{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649ec53f-7a98-4a46-a0c9-e1922cdddeb5",
   "metadata": {},
   "source": [
    "# PyTorch mutual information neural estimation tests\n",
    "\n",
    "Trivial tests with multivariate Gaussian and uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f374d-198f-42e7-b2c2-a0cb1b35913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd27da-f5c1-4ac1-999a-6fae2e0b3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e487ff1-fa67-4bec-a4d4-88a6ce973b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchkld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c265f9-3930-41e7-8d5c-6f1ec2abee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = \"cpu\"\n",
    "print(\"Device: \" + device)\n",
    "print(f\"Devices count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43237284-a85b-4f61-bea4-5c38e5c3ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d855a-4c33-4c62-9625-6523f9441af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.modules import *\n",
    "from misc.utils import *\n",
    "from misc.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38298fb-5baa-4eee-ac13-6804eca6b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3c574-93ee-421d-bd50-b0237c2cc46a",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf0b9f-3d8c-4dfb-9137-cc100f5e811d",
   "metadata": {},
   "source": [
    "Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d317a7bf-f008-4cf4-9893-cad69848af85",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    #torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17bcf1-bd5e-42f7-a7b9-914ab78d377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"dataset\"] = \"MNIST\"\n",
    "#config[\"dataset\"] = \"CIFAR10\"\n",
    "config[\"n_copies\"] = 2\n",
    "config[\"n_classes\"] = 10\n",
    "config[\"mutual_information\"] = config[\"n_copies\"] * np.log(config[\"n_classes\"])\n",
    "aggregate = lambda x_list: torch.cat(x_list, dim=1)\n",
    "\n",
    "train_dataset = getattr(torchvision.datasets, config[\"dataset\"])(root=\"./.cache\", download=True, transform=image_transform)\n",
    "test_dataset  = getattr(torchvision.datasets, config[\"dataset\"])(root=\"./.cache\", download=True, transform=image_transform, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a4f56-289f-4a69-90bb-3a8782de996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader  = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae29b44e-a9a8-4765-8197-30cc1554ba51",
   "metadata": {},
   "source": [
    "## Estimating MI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b813b1-a532-44ae-94d9-800a7d929360",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2e80b-0cb5-451e-99f1-4a16ab552740",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_T_network(torchkld.mutual_information.MINE):\n",
    "    def __init__(self, X_channels: int=1, Y_channels: int=1) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv2d_1 = torch.nn.Conv2d(X_channels + Y_channels, 64, 3, padding='same')\n",
    "        self.conv2d_2 = torch.nn.Conv2d(64, 128, 3, padding='same')\n",
    "        self.conv2d_3 = torch.nn.Conv2d(128, 128, 3, padding='same')\n",
    "\n",
    "        self.linear_1 = torch.nn.Linear(128*7*7, 128)\n",
    "        self.linear_2 = torch.nn.Linear(128, 1)\n",
    "\n",
    "        self.pooling = torch.nn.AvgPool2d(2)\n",
    "        self.activation = torch.nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor, marginalize: bool=False) -> torch.Tensor:\n",
    "        x, y = super().forward(x, y, marginalize)\n",
    "        \n",
    "        z = torch.cat([x, y], axis=1)\n",
    "\n",
    "        z = self.conv2d_1(z)\n",
    "        z = self.pooling(z)\n",
    "        z = self.activation(z)\n",
    "\n",
    "        z = self.conv2d_2(z)\n",
    "        z = self.pooling(z)\n",
    "        z = self.activation(z)\n",
    "\n",
    "        z = self.conv2d_3(z)\n",
    "        z = self.activation(z)\n",
    "\n",
    "        z = z.flatten(start_dim=1)\n",
    "        \n",
    "        z = self.linear_1(z)\n",
    "        z = self.activation(z)\n",
    "\n",
    "        z = self.linear_2(z)\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b319980-e6c5-4c4c-a4cb-48643d2636b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_T_network(config[\"n_copies\"], config[\"n_copies\"]).to(device)\n",
    "total_parameters = sum(parameter.numel() for parameter in model.parameters())\n",
    "print(f\"Total parameters: {total_parameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc680af-62d8-4c9e-83c3-92379950ff1c",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772fa747-01e2-427a-af60-38fd309daeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss.\n",
    "biased = False\n",
    "ema_multiplier = 1.0e-2\n",
    "marginalize = \"permute\" # \"permute\", \"product\"\n",
    "\n",
    "losses = {\n",
    "    \"DonskerVaradhan\": torchkld.loss.DonskerVaradhanLoss(biased=biased, ema_multiplier=ema_multiplier),\n",
    "    \"NWJ\": torchkld.loss.NWJLoss(),\n",
    "    \"Nishiyama\": torchkld.loss.NishiyamaLoss(),\n",
    "    \"InfoNCE\": torchkld.loss.InfoNCELoss(),\n",
    "}\n",
    "\n",
    "loss_name = \"DonskerVaradhan\"\n",
    "loss = losses[loss_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b1ca3-f0cf-4188-825c-7de35364ec9f",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24859d48-3d76-41a5-8c1e-27f6b11c638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.0e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594148f1-d379-4574-a65a-3ec8607fc220",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59ce4e-2751-49ad-a784-5d81e1a1135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249b382-75ff-48da-858e-837231c5dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs used to average the estimate.\n",
    "average_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f14e6-1a3b-4f27-bae1-7d6e3257c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_pairs_preserve_labels(\n",
    "    samples: torch.Tensor,\n",
    "    labels: torch.Tensor\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    unique_labels = labels.unique()\n",
    "\n",
    "    subsets_indices = []\n",
    "    permuted_subsets_indices = []\n",
    "    for label in unique_labels:\n",
    "        subset_indices = (labels == label).nonzero().squeeze(dim=1)\n",
    "        subsets_indices.append(subset_indices)\n",
    "        permuted_subsets_indices.append(subset_indices[torch.randperm(subset_indices.shape[0])])\n",
    "\n",
    "    indices = torch.cat(subsets_indices, axis=0)\n",
    "    permuted_indices = torch.cat(permuted_subsets_indices, axis=0)\n",
    "\n",
    "    return samples[indices], samples[permuted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b2efdb-bc31-4282-8f1c-3fad8128462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permute_aggregate(\n",
    "    samples: torch.Tensor,\n",
    "    labels: torch.Tensor,\n",
    "    aggregate=lambda x_list : torch.cat(x_list, dim=1),\n",
    "    n_copies: int=1\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    x_1_list = []\n",
    "    x_2_list = []\n",
    "    for index in range(config[\"n_copies\"]):\n",
    "        x_1, x_2 = permute_pairs_preserve_labels(samples, labels)\n",
    "        \n",
    "        permutation = torch.randperm(x_1.shape[0])\n",
    "        x_1_list.append(x_1[permutation])\n",
    "        x_2_list.append(x_2[permutation])\n",
    "\n",
    "    return aggregate(x_1_list), aggregate(x_2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99a2a2-389d-499d-800b-eef120ce0202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from tqdm import trange\n",
    "\n",
    "n_epochs = 2000\n",
    "\n",
    "history = defaultdict(list)\n",
    "for epoch in trange(1, n_epochs + 1, mininterval=1):    \n",
    "    # Training.\n",
    "    for index, batch in enumerate(train_dataloader):\n",
    "        x, y = batch\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        x_1, x_2 = permute_aggregate(x, y, aggregate, config[\"n_copies\"])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        T_joined   = model(x_1.to(device), x_2.to(device))\n",
    "        T_marginal = model(x_1.to(device), x_2.to(device), marginalize=marginalize)\n",
    "        _loss = loss(T_joined, T_marginal)\n",
    "        _loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    history[\"train_mutual_information\"].append(model.get_mutual_information(train_dataloader, loss, device, marginalize=marginalize, transform=permute_aggregate))\n",
    "    history[\"test_mutual_information\"].append(model.get_mutual_information(test_dataloader, loss, device, marginalize=marginalize, transform=permute_aggregate))\n",
    "\n",
    "    if epoch % 5 == 0:        \n",
    "        clear_output(wait=True)\n",
    "        plot_estimated_MI_trainig(config[\"mutual_information\"], np.arange(1, epoch+1), history[\"train_mutual_information\"])\n",
    "        plot_estimated_MI_trainig(config[\"mutual_information\"], np.arange(1, epoch+1), history[\"test_mutual_information\"])\n",
    "        print(f\"Current estimate: {history['test_mutual_information'][-1]:.2f}\")\n",
    "        print(f\"Running median: {np.median(history['test_mutual_information'][-average_epochs:]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a10f0c-de29-492a-8e1b-7dc0735a0701",
   "metadata": {},
   "source": [
    "### Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c08d1-93e0-4235-b153-0235f16cf287",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # Dataset.\n",
    "    \"dataset_type\": dataset_type,\n",
    "    \"mutual_information\": mutual_information,\n",
    "\n",
    "    # Model.\n",
    "    \"inner_dim\": inner_dim,\n",
    "\n",
    "    # Loss.\n",
    "    \"loss_name\": loss_name,\n",
    "    \"biased\": biased,\n",
    "    \"ema_multiplier\": ema_multiplier,\n",
    "\n",
    "    # Training.\n",
    "    \"n_samples\": n_samples,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"n_epochs\": n_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "\n",
    "    # Saving the results.\n",
    "    \"average_epochs\": average_epochs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac767f1-0fce-4401-89b5-32179b4ccd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "experiment_name = f\"{dataset_type}_{dimension}_{mutual_information:.1f}_{n_samples}__{datetime.now().strftime('%d-%b-%Y_%H:%M:%S')}\"\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6211394-7714-4e86-bf96-b12e1e5c2ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(os.path.abspath(os.path.join(os.path.abspath(os.getcwd()), \"../../data/synthetic\")))\n",
    "experiment_path = data_path / f\"{dataset_type}\" / loss_name / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590989b-d18f-4907-9418-84395f30143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(history, parameters, experiment_path, average_epochs=average_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d18d38-9eef-4353-997c-2dca0486b099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
