{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649ec53f-7a98-4a46-a0c9-e1922cdddeb5",
   "metadata": {},
   "source": [
    "# PyTorch mutual information neural estimation tests\n",
    "\n",
    "Trivial tests with multivariate Gaussian and uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f374d-198f-42e7-b2c2-a0cb1b35913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd27da-f5c1-4ac1-999a-6fae2e0b3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e487ff1-fa67-4bec-a4d4-88a6ce973b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchkld\n",
    "import mutinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c265f9-3930-41e7-8d5c-6f1ec2abee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = \"cpu\"\n",
    "print(\"Device: \" + device)\n",
    "print(f\"Devices count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43237284-a85b-4f61-bea4-5c38e5c3ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4e461-ec35-45d6-8996-600d6f6389ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mutinfo.distributions.base import *\n",
    "from mutinfo.distributions.tools import mapped_multi_rv_frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d855a-4c33-4c62-9625-6523f9441af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc.modules import *\n",
    "from misc.utils import *\n",
    "from misc.plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3c574-93ee-421d-bd50-b0237c2cc46a",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec522a-ba8b-457b-bf85-acab7e9af14a",
   "metadata": {},
   "source": [
    "Experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675a0ff-d992-4a21-9915-044e302f1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_information = 10.0\n",
    "\n",
    "dataset_type = \"CorrelatedNormal\"\n",
    "assert dataset_type in [\"CorrelatedNormal\", \"CorrelatedStudent\", \"CorrelatedStudent_arcsinh\", \"CorrelatedUniform\", \"SmoothedUniform\", \"UniformlyQuantized\"]\n",
    "degrees_of_freedom = 2 # For Student's distribution\n",
    "\n",
    "dimension = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014ad06-556c-44b3-aac6-2be4c2bda9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomize_interactions = True\n",
    "shuffle_interactions = True\n",
    "\n",
    "if dataset_type == \"CorrelatedNormal\":\n",
    "    random_variable = CorrelatedNormal(mutual_information, dimension, dimension, randomize_interactions=randomize_interactions, shuffle_interactions=shuffle_interactions)\n",
    "\n",
    "elif dataset_type in [\"CorrelatedStudent\", \"CorrelatedStudent_arcsinh\"]:\n",
    "    random_variable = CorrelatedStudent(\n",
    "        mutual_information, dimension, dimension, degrees_of_freedom, randomize_interactions=randomize_interactions, shuffle_interactions=shuffle_interactions\n",
    "    )\n",
    "\n",
    "    if dataset_type == \"CorrelatedStudent_arcsinh\":\n",
    "        random_variable = mapped_multi_rv_frozen(random_variable, lambda x, y: (np.arcsinh(x), np.arcsinh(y)), lambda x, y: (np.sinh(x), np.sinh(y)))\n",
    "\n",
    "    dataset_type += f\"_dof_{degrees_of_freedom}\"\n",
    "    \n",
    "elif dataset_type == \"CorrelatedUniform\":\n",
    "    random_variable = CorrelatedUniform(mutual_information, dimension, dimension, randomize_interactions=randomize_interactions, shuffle_interactions=shuffle_interactions)\n",
    "\n",
    "elif dataset_type == \"SmoothedUniform\":\n",
    "    random_variable = SmoothedUniform(mutual_information, dimension, dimension, randomize_interactions=randomize_interactions)\n",
    "\n",
    "elif dataset_type == \"UniformlyQuantized\":\n",
    "    from scipy.stats import norm\n",
    "    \n",
    "    random_variable = UniformlyQuantized(mutual_information, dimension, norm(loc=0.0, scale=1.0), randomize_interactions=randomize_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0439dd-d591-42d0-ae35-cd6a864cab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10*1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae29b44e-a9a8-4765-8197-30cc1554ba51",
   "metadata": {},
   "source": [
    "## Estimating MI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf0b9f-3d8c-4dfb-9137-cc100f5e811d",
   "metadata": {},
   "source": [
    "Dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad20d2-5c06-4462-ade2-e7266fcf87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = random_variable.rvs(n_samples)\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(x, dtype=torch.float32),\n",
    "    torch.tensor(y, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "x, y = random_variable.rvs(n_samples)\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(x, dtype=torch.float32),\n",
    "    torch.tensor(y, dtype=torch.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a4f56-289f-4a69-90bb-3a8782de996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader  = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b813b1-a532-44ae-94d9-800a7d929360",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b319980-e6c5-4c4c-a4cb-48643d2636b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_dim = 128\n",
    "\n",
    "model = BasicDenseT(dimension, dimension, inner_dim=inner_dim).to(device)\n",
    "total_parameters = sum(parameter.numel() for parameter in model.parameters())\n",
    "print(f\"Total parameters: {total_parameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc680af-62d8-4c9e-83c3-92379950ff1c",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772fa747-01e2-427a-af60-38fd309daeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss.\n",
    "biased = False\n",
    "ema_multiplier = 1.0e-2\n",
    "marginalize = \"permute\" # \"permute\", \"product\"\n",
    "\n",
    "losses = {\n",
    "    \"DonskerVaradhan\": torchkld.loss.DonskerVaradhanLoss(biased=biased, ema_multiplier=ema_multiplier),\n",
    "    \"NWJ\": torchkld.loss.NWJLoss(),\n",
    "    \"Nishiyama\": torchkld.loss.NishiyamaLoss(),\n",
    "    \"InfoNCE\": torchkld.loss.InfoNCELoss(),\n",
    "}\n",
    "\n",
    "loss_name = \"DonskerVaradhan\"\n",
    "loss = losses[loss_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b1ca3-f0cf-4188-825c-7de35364ec9f",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24859d48-3d76-41a5-8c1e-27f6b11c638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1.0e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594148f1-d379-4574-a65a-3ec8607fc220",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59ce4e-2751-49ad-a784-5d81e1a1135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0249b382-75ff-48da-858e-837231c5dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs used to average the estimate.\n",
    "average_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd99a2a2-389d-499d-800b-eef120ce0202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from tqdm import trange\n",
    "\n",
    "n_epochs = 2000\n",
    "\n",
    "history = defaultdict(list)\n",
    "for epoch in trange(1, n_epochs + 1, mininterval=1):    \n",
    "    # Training.\n",
    "    for index, batch in enumerate(train_dataloader):\n",
    "        x, y = batch\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        T_joined   = model(x.to(device), y.to(device))\n",
    "        T_marginal = model(x.to(device), y.to(device), marginalize=marginalize)\n",
    "        _loss = loss(T_joined, T_marginal)\n",
    "        _loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    history[\"train_mutual_information\"].append(model.get_mutual_information(train_dataloader, loss, device, marginalize=marginalize))\n",
    "    history[\"test_mutual_information\"].append(model.get_mutual_information(test_dataloader, loss, device, marginalize=marginalize))\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        clear_output(wait=True)\n",
    "        plot_estimated_MI_trainig(mutual_information, np.arange(1, epoch+1), history[\"train_mutual_information\"])\n",
    "        plot_estimated_MI_trainig(mutual_information, np.arange(1, epoch+1), history[\"test_mutual_information\"])\n",
    "        print(f\"Current estimate: {history['test_mutual_information'][-1]:.2f}\")\n",
    "        print(f\"Running median: {np.median(history['test_mutual_information'][-average_epochs:]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a10f0c-de29-492a-8e1b-7dc0735a0701",
   "metadata": {},
   "source": [
    "### Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c08d1-93e0-4235-b153-0235f16cf287",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # Dataset.\n",
    "    \"dataset_type\": dataset_type,\n",
    "    \"mutual_information\": mutual_information,\n",
    "\n",
    "    # Model.\n",
    "    \"inner_dim\": inner_dim,\n",
    "\n",
    "    # Loss.\n",
    "    \"loss_name\": loss_name,\n",
    "    \"biased\": biased,\n",
    "    \"ema_multiplier\": ema_multiplier,\n",
    "\n",
    "    # Training.\n",
    "    \"n_samples\": n_samples,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"n_epochs\": n_epochs,\n",
    "    \"learning_rate\": learning_rate,\n",
    "\n",
    "    # Saving the results.\n",
    "    \"average_epochs\": average_epochs,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac767f1-0fce-4401-89b5-32179b4ccd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "experiment_name = f\"{dataset_type}_{dimension}_{mutual_information:.1f}_{n_samples}__{datetime.now().strftime('%d-%b-%Y_%H:%M:%S')}\"\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6211394-7714-4e86-bf96-b12e1e5c2ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(os.path.abspath(os.path.join(os.path.abspath(os.getcwd()), \"../../data/synthetic\")))\n",
    "experiment_path = data_path / f\"{dataset_type}\" / loss_name / experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590989b-d18f-4907-9418-84395f30143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(history, parameters, experiment_path, average_epochs=average_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d18d38-9eef-4353-997c-2dca0486b099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
